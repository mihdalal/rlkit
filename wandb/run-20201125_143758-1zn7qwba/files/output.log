mounting: MountLocal@/home/mdalal/research/doodad
mounting: MountLocal@/home/mdalal/research/rlkit
mounting: MountLocal@/home/mdalal/research/hrl-exp
mounting: MountLocal@/home/mdalal/research/carbongym-utils
mounting: MountLocal@/home/mdalal/research/carbongym-objs
mounting: MountLocal@/home/mdalal/research/d4rl
mounting: MountLocal@/home/mdalal/research/rlkit/data
mounting: MountLocal@/home/mdalal/research/rlkit/scripts
2020-11-25 14:38:03.617334 EST | Variant:
2020-11-25 14:38:03.617729 EST | {
  "env_class": "hinge_cabinet",
  "env_kwargs": {
    "delta": 0.3,
    "dense": false,
    "image_obs": true,
    "fixed_schema": true,
    "multitask": false,
    "action_scale": 1.4
  },
  "algorithm": "dreamer_v2",
  "version": "normal",
  "replay_buffer_size": 1000000,
  "algorithm_kwargs": {
    "num_epochs": 5,
    "num_eval_steps_per_epoch": 10,
    "num_trains_per_train_loop": 10,
    "num_expl_steps_per_train_loop": 50,
    "min_num_steps_before_training": 10,
    "num_pretrain_steps": 10,
    "num_train_loops_per_epoch": 1,
    "batch_size": 30,
    "use_wandb": true,
    "max_path_length": 6
  },
  "vf_kwargs": {
    "num_layers": 3
  },
  "actor_kwargs": {
    "discrete_continuous_dist": false
  },
  "model_kwargs": {
    "model_hidden_size": 400,
    "stochastic_state_size": 60,
    "deterministic_state_size": 400,
    "gru_layer_norm": false
  },
  "trainer_kwargs": {
    "discount": 0.8333333333333334,
    "reward_scale": 1.0,
    "actor_lr": 8e-05,
    "vf_lr": 8e-05,
    "world_model_lr": 0.0006,
    "use_amp": true,
    "opt_level": "O1",
    "gradient_clip": 100.0,
    "lam": 0.95,
    "free_nats": 3.0,
    "optimizer_class": "apex_adam",
    "kl_loss_scale": 1.0,
    "image_loss_scale": 1.0,
    "reward_loss_scale": 1.0,
    "pred_discount_loss_scale": 10.0,
    "transition_loss_scale": 0.0,
    "entropy_loss_scale": 0.0,
    "use_pred_discount": true,
    "target_update_period": 1,
    "imagination_horizon": 7
  },
  "num_expl_envs": 8,
  "num_eval_envs": 1,
  "expl_amount": 0.3,
  "path_length_specific_discount": true,
  "seed": "66599",
  "exp_id": "0",
  "exp_prefix": "11-25-test",
  "instance_type": "None"
}
/home/mdalal/miniconda3/envs/hrl-exp-env/lib/python3.7/site-packages/glfw/__init__.py:834: GLFWError: (65544) b'X11: The DISPLAY environment variable is missing'
  warnings.warn(message, GLFWError)
/home/mdalal/miniconda3/envs/hrl-exp-env/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Box bound precision lowered by casting to float32[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
Reading configurations for Franka
[40m[37mInitializing Franka sim[0m
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Found 8 GPUs for rendering. Using device 1.
Traceback (most recent call last):
  File "/home/mdalal/research/rlkit/rlkit/../scripts/run_experiment_from_doodad.py", line 60, in <module>
    run_experiment_here(method_call, log_dir=output_dir, **run_experiment_kwargs)
  File "/home/mdalal/research/rlkit/rlkit/launchers/launcher_util.py", line 168, in run_experiment_here
    return experiment_function(variant)
  File "/home/mdalal/research/rlkit/rlkit/torch/model_based/dreamer/experiments/kitchen_dreamer.py", line 200, in experiment
    **variant["algorithm_kwargs"],
  File "/home/mdalal/research/rlkit/rlkit/core/batch_rl_algorithm.py", line 38, in __init__
    use_wandb=use_wandb,
  File "/home/mdalal/research/rlkit/rlkit/core/rl_algorithm.py", line 48, in __init__
    wandb.watch(network, log="all", log_freq=1)
  File "/home/mdalal/miniconda3/envs/hrl-exp-env/lib/python3.7/site-packages/wandb/sdk/wandb_watch.py", line 41, in watch
    raise ValueError("You must call `wandb.init` before calling watch")
ValueError: You must call `wandb.init` before calling watch
